{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalProjectComputerVision",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOvJLS1rJP/LRYR0N5z4UJo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oscar-defelice/Computer-Vision-Hands-on/blob/main/FinalProjectComputerVision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aswZEE4AcpG6"
      },
      "source": [
        "# Computer Vision Hands-on\n",
        "## Final Project\n",
        "\n",
        "Questo notebook costituisce il final project del corso *Computer Vision Hands-on*.\n",
        "\n",
        "### Obiettivo\n",
        "\n",
        "> Costruire un modello di riconoscimento immagini tramite *Siamese Network*. Il modello dovrà avere una AUC/ROC di almeno 0.87 sul test set.\n",
        "\n",
        "Il dataset da utilizzare sarà il famoso [MNIST](https://www.tensorflow.org/datasets/catalog/mnist). \n",
        "\n",
        "Utilizzeremo questo dataset per costruire e allenare una siamese network e avere un modello che riconosca le cifre all'interno di un database.\n",
        "\n",
        "#### Costruire il test database\n",
        "Il database sarà costituito $5000$ immagini prese dal dataset di test.\n",
        "\n",
        "Per provare l'algoritmo inserite un'immagine e date il predict al modello: dovrebbe darvi una corrispondenza. Potete usare le funzioni sviluppate insieme nella [lezione sulle Siamese Network](https://github.com/DeepLearningItalia/Computer-Vision-Hands-on/tree/main/Lectures_src/SiameseNetwork).\n",
        "\n",
        "#### Costruire il training set\n",
        "Utilizzate `tensorflow.keras` e costruite le triplette di training, ricordandovi che affinché il modello apprenda efficacemente, è opportuno utilizzare *Hard-Triplets*, cioè immagini con poco \"distanza\" tra *Positive* e *Negative*.\n",
        "\n",
        "[Questo video](https://www.coursera.org/lecture/sequence-models-in-nlp/training-testing-KDqML) può esservi utile per capire come costruire il training set.\n",
        "\n",
        "#### Costruire il modello\n",
        "\n",
        "Il modello è una semplice rete neurale convoluzionale (potete usare l'architettura che preferite - ImageNet, AlexNet, ResNet50, etc. - e che vi dia le performance desiderate).\n",
        "\n",
        "Occorre fare attenzione: \n",
        "\n",
        "1. Keras non ha un layer TripletLoss: dovremmo costruirlo noi. Il codice è fornito in questo notebook.\n",
        "2. Occorre costruire due reti: una per il training che prende in input le triplette, una per le predizioni, che prende in input due immagini e ritorna il punteggio di similarità tra queste. Le due reti devono condividere gli stessi pesi. In questo notebook fornisco un esempio con reti fully connected da modificare con la vostra architettura di rete.\n",
        "\n",
        "#### Bonus:\n",
        "Deploy del modello (solo quello previsionale) con TensorFlow.JS in modo da poter caricare un'immagine su una pagina web e che questa restituisca un messaggio dicendo se ha riconosciuto o no la cifra nella foto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tAY5uURo2aQ"
      },
      "source": [
        "## Import delle librerie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OG5vA__oplgf"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from pylab import *\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Lambda, Flatten, Dense\n",
        "from tensorflow.keras.initializers import glorot_uniform,he_uniform\n",
        "\n",
        "from tensorflow.keras.layers import Layer, InputSpec\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import plot_model,normalize\n",
        "\n",
        "from sklearn.metrics import roc_curve,roc_auc_score"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OFtX1XeqWQ0"
      },
      "source": [
        "Una funzione per fare il plot delle immagini a schermo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUmdwCJiqCPr"
      },
      "source": [
        "def DrawPics(tensor,nb=0,template='{}',classnumber=None):\n",
        "    if (nb==0):\n",
        "        N = tensor.shape[0]\n",
        "    else:\n",
        "        N = min(nb,tensor.shape[0])\n",
        "    fig=plt.figure(figsize=(16,2))\n",
        "    nbligne = floor(N/20)+1\n",
        "    for m in range(N):\n",
        "        subplot = fig.add_subplot(nbligne,min(N,20),m+1)\n",
        "        axis(\"off\")\n",
        "        plt.imshow(tensor[m,:,:,0],vmin=0, vmax=1,cmap='Greys')\n",
        "        if (classnumber!=None):\n",
        "            subplot.title.set_text((template.format(classnumber)))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkGSCA7uqmEA"
      },
      "source": [
        "### Importare il dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JWzJeKtqpEN"
      },
      "source": [
        "n_classes = 10\n",
        "img_rows, img_cols = 28, 28\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "def buildDataSet():\n",
        "    \"\"\"Build dataset for train and test\n",
        "    \n",
        "    \n",
        "    returns:\n",
        "        dataset : list of lengh 10 containing images for each classes of shape (?,28,28,1)\n",
        "    \"\"\"\n",
        "    (x_train_origin, y_train_origin), (x_test_origin, y_test_origin) = mnist.load_data()\n",
        "\n",
        "    assert K.image_data_format() == 'channels_last'\n",
        "    x_train_origin = x_train_origin.reshape(x_train_origin.shape[0], img_rows, img_cols, 1)\n",
        "    x_test_origin = x_test_origin.reshape(x_test_origin.shape[0], img_rows, img_cols, 1)\n",
        "    \n",
        "    dataset_train = []\n",
        "    dataset_test = []\n",
        "    \n",
        "    #Sorting images by classes and normalize values 0=>1\n",
        "    for n in range(n_classes):\n",
        "        images_class_n = np.asarray([row for idx,row in enumerate(x_train_origin) if y_train_origin[idx]==n])\n",
        "        dataset_train.append(images_class_n/255)\n",
        "        \n",
        "        images_class_n = np.asarray([row for idx,row in enumerate(x_test_origin) if y_test_origin[idx]==n])\n",
        "        dataset_test.append(images_class_n/255)\n",
        "        \n",
        "    return dataset_train,dataset_test,x_train_origin,y_train_origin,x_test_origin,y_test_origin"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUCici2Wr49f"
      },
      "source": [
        "#### Visualizzare alcuni elementi del dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "hpotaWkur3Ir",
        "outputId": "2c8c8bf4-b64b-462a-ae03-240a07772a63"
      },
      "source": [
        "dataset_train,dataset_test,x_train_origin,y_train_origin,x_test_origin,y_test_origin = buildDataSet()\n",
        "print(\"Checking shapes for class 0 (train) : \",dataset_train[0].shape)\n",
        "print(\"Checking shapes for class 0 (test) : \",dataset_test[0].shape)\n",
        "print(\"Checking first samples\")\n",
        "for i in range(2):\n",
        "    DrawPics(dataset_train[i],5,template='Train {}',classnumber=i)\n",
        "    DrawPics(dataset_test[i],5,template='Test {}',classnumber=i)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking shapes for class 0 (train) :  (5923, 28, 28, 1)\n",
            "Checking shapes for class 0 (test) :  (980, 28, 28, 1)\n",
            "Checking first samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA10AAACLCAYAAACa9PPwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUjklEQVR4nO3deWxV5brH8feVQShTKAIXpAhBETVEICTGyKCIkaMSZoQLAjIYwSqIAyJpjiJouYoMclEsV8YEmQQumIsCiqKCAYQGlYBGmVqRMpRBZlj3D7Hp8wB779W93u7u1e8nOcn6da/h7TkPu/s9az37tZ7nGQAAAACAGzckegAAAAAAEGZMugAAAADAISZdAAAAAOAQky4AAAAAcIhJFwAAAAA4xKQLAAAAABwqdZMua+3/WWv7J3ocgCvUOMKOGkeYUd8Iu9Ja40kx6bLWnir0n8vW2jOFch8/5/I871+e580p4jhSrbXLrLV/WWv3Wmv/syjnATRqHGFHjSPMqG+EHTUev7KJHkAsPM+r/M+2tXaPMWaw53lr9X7W2rKe5110OJT/NsacN8bUNsY0M8Z8aq3N9jzvJ4fXRClAjSPsqHGEGfWNsKPG45cUd7qux1p7v7X2gLV2lLX2oDFmlrW2urV2lbU2z1p77Mp2vULHrLfWDr6yPcBa+4219p0r+/5urf3Xda5VyRjTzRiT4XneKc/zvjHG/K8x5oli+FVRSlHjCDtqHGFGfSPsqPHYJfWk64r/MMakGmNuMcY8Zf7+nWZdyfWNMWeMMdMiHH+PMWaXMeYmY8x/GWP+x1prr7FfY2PMRc/zdhf6WbYx5q54fwEgCmocYUeNI8yob4QdNR6DMEy6Lhtj/u153jnP8854nnfE87ylnued9jzvpDFmvDGmbYTj93qel+V53iVjzBxjTB3z9y1LrbIx5oT62XFjTJUAfgcgEmocYUeNI8yob4QdNR6DpOjpiiLP87yz/wRrbYoxZpIxpoMxpvqVH1ex1pa58j+mdvCfDc/zTl+ZWFe+xn6njDFV1c+qGmNOxjF2IBbUOMKOGkeYUd8IO2o8BmG40+Wp/IIx5nZjzD2e51U1xrS58vNr3ab0Y7cxpqy19rZCP7vbGFPiG/eQ9KhxhB01jjCjvhF21HgMwjDp0qqYv58dzbfWphpj/h3EST3P+8sY84kxZqy1tpK19j5jTCdjzLwgzg/4QI0j7KhxhBn1jbCjxq8hjJOuycaYisaYw8aYTcaY1QGee9iVcx8yxiwwxgxNhq+oROhQ4wg7ahxhRn0j7Kjxa7Cep+8IAgAAAACCEsY7XQAAAABQYjDpAgAAAACHmHQBAAAAgENMugAAAADAISZdAAAAAOBQ2Siv89WGySfehedKG2o8+VDj/lDjyYcajx31nXyob3+o8eRzzRrnThcAAAAAOMSkCwAAAAAcYtIFAAAAAA4x6QIAAAAAh5h0AQAAAIBDTLoAAAAAwCEmXQAAAADgEJMuAAAAAHCISRcAAAAAOMSkCwAAAAAcYtIFAAAAAA4x6QIAAAAAh5h0AQAAAIBDTLoAAAAAwCEmXQAAAADgUNlED6Ak2L9/v8hTpkwRedKkSSI///zzIg8fPlzktLS0AEcHuLdr1y6R77zzTpEvX74ccf/GjRu7GRgAwGRnZ4vcokULkevXry/y8uXLRb7ttttETklJCXB0AGLBnS4AAAAAcIhJFwAAAAA4ZD3Pi/R6xBeTVU5Ojsh33323yPn5+b7OV716dZHz8vKKNrBg2ERePAmFssajWbdunchjx44V+bvvvhNZP17YqlUrkdPT00Xu1q2byDfcEOj/v0ON+xPKGt+7d6/IDRo0ENlvzX3wwQciDxkypEjjCgg1HrtQ1remHy9s2bKlr+P79+8v8syZM+MeUxyob39CU+O5ubkF21u2bBGvde7cOa5z6/lMamqqyDt37hS5Vq1acV0vimvWOHe6AAAAAMAhJl0AAAAA4BCTLgAAAABwqNR8ZXzh5//vv/9+8dqxY8dEtlY+ilmtWjWRb7zxRpEPHTok8m+//SbyLbfcInKZMmWiDxgIkO7h0v0ruocrGr2/zocPHxZZ/xsC4pWRkSGy7uHy29M1bNgwkQ8ePChyr169RNZfwQ3E6+zZswXbL730knht5cqVcZ373nvvjet4IBZHjhwR+dNPPxV5/PjxBdu//PKLeE1/9vZLH6+/n6Fjx44iL1q0SGT9Wd0F7nQBAAAAgENMugAAAADAISZdAAAAAOBQaNbpunDhgsh6DZcOHToUbO/Zs0e8pv870M+Ftm3bVuTCz6Qac/WaRfp8H374ociDBg0yDrH+hT9JU+Na4ef/jZE1r59d/uOPPyIeq7Vo0ULkS5cuiazXjNEc93RR4/4kbY3rZ/LbtGlTsL1//37x2okTJ0SOd204vTbd0qVLRY53TZkoqPHYJW19a4V7XDp16iRe27Vrl8jx1vfGjRtF9rvuV5yob39KbI2fO3dOZP3ZQ/eTFxbts7drc+fOFblPnz5Bnp51ugAAAACguDHpAgAAAACHmHQBAAAAgEOhWadLr2kxbdq0wM791VdfifzXX3+J3KVLF5E/+eQTkbdt2xbYWFB6bd68WeSpU6eK/PHHHxds634Uv8//Z2ZmiqzPV7hHEnBF9xLu3LkzQSMB3Dt+/HjBtu5RDJruGdPrgOm+XpROuv97zJgxIs+fP19k3c8dpAoVKoh80003iXzgwAFn1w4Kd7oAAAAAwCEmXQAAAADgEJMuAAAAAHAoaXu69Bot+rnSSOuP6R6sbt26idy3b1+R09LSRL7jjjtEHjVqlMhLliyJeSzA9ehewnbt2sV8rO7B8itazcZ7fiAWr732WmDnWr16tcgbNmwQWa+/CATtjTfeENlPfQf9npubmyuyXr+Uni4Yc/XnkMmTJydoJFd/9tbv2Y888khxDqdIuNMFAAAAAA4x6QIAAAAAh5h0AQAAAIBDSdPTlZOTI3Lz5s1Fzs/PF9laK3KfPn0KtrOyssRrP//8s8j69V69eomckpIict26dUXWayLNmzdP5FdeeUVk3TOG0kk/O92zZ0+RdV1VrFhR5Hr16hVs638PeXl5Ea+tz1WpUiWRT506FXEsQFFkZ2eLHE8fyZQpU0ROT0+PuP+xY8dE1j0z0TLgl/5cEs/76NNPPy3yQw89JPLnn38usv5coy1YsEBkvRaj/tyDcNJ/66dPnx7o+Qv3hOkeLb3G7YwZM0R+5513RD537lygYysOfHICAAAAAIeYdAEAAACAQ0y6AAAAAMChEtvTdfjwYZEnTJggsn4ev3bt2iI3bNhQ5KFDhxZsly9fXrzWrFmziDlep0+fFvntt98WeerUqYFeD8lh8+bNIut1uKI976+fuV+0aFHB9rp16yLuq82aNUvke+65R2R9PsCFeHpcovVwaX77a+hjRDQnT54Uefv27SK/9957EY+vUaNGwXadOnXEa23atBFZfyYqV66cyLoPPprly5eLfPbsWZHp6Sod9FpX3377bcT99ftizZo1Rc7IyBB58ODBBdu6Zu+77z6Rx44dK3JqaqrI58+fv+65jTFm5syZ1xt2wvBXBAAAAAAcYtIFAAAAAA4x6QIAAAAAh0pMT9fFixdFfvHFF0WeP3++yNWqVRP5s88+E/nWW28V+cKFC/EOMTC///57ooeABNB9UT169Ii4v147S/dlResPKKxVq1Yi6/6XLl26RDy+devWIus1YdasWRPzWIB/jBw5ssjH1q9f39f+ly5dEvngwYNFvjZgjDG5ubki6/fRLVu2iBytL3D48OEF26NHj/Y1liNHjog8YsQIX8ejdNqzZ4/IP/74o6/jdQ+X/jfhh/7Mo7Om1+k6fvx4ka9dXLjTBQAAAAAOMekCAAAAAIeYdAEAAACAQyWmp2vfvn0i6x4ubdOmTSI3btw44v7Rng0FXNN9VHpNF23y5MkiDxw4MOZrNW/eXORVq1aJXKlSpZjPZczVa9uxZguCoNdl+frrr2M+Vq8rFM3ChQtFpucF8dq4caPIP/zwQ4JGYkyVKlVEHjNmjMjjx4/3db7XX39d5ClTphRtYCjR9FpYfvui9DpcxUnPAxYvXpygkcSOO10AAAAA4BCTLgAAAABwqMQ8XvjMM8+I7HmeyPqrWKM9TphIly9fFll/Taz+3RBOOTk5Iufn54us60R/pXU8UlNTAzvXtega1r8LEAv9yFO0r9QeMGBAwXajRo18XSszM9PX/oB2/vx5kbOzs0XW74M6t2zZUmS9jEjlypXjHWLMY4k2Nr+PI6J00G0PgwcPTtBIkhN3ugAAAADAISZdAAAAAOAQky4AAAAAcChhPV3btm0TWX9VsLVW5B49ejgfU1B0X4L+XfSz0wiHgwcPity+fXuRDx8+LHK0/pWSRPcynDlzRuRk+l2QOH379hU5Wi9g06ZNRc7Kyirytf32Ifbu3Vvkzp07F/naCIdJkyaJ/NZbb4kc7X1w9OjRIgfZw6WXIIk2Nv05ZNmyZc7GhpJjzpw5Is+ePTvi/nXq1BG5devWIpcrVy6QcRXFww8/LPLIkSNFnjhxYsTjE9GLziclAAAAAHCISRcAAAAAOMSkCwAAAAAcSlhP19mzZ0U+d+6cyHXr1hX50UcfdT6mWF28eFHkqVOnRty/e/fuIr/66quBjwmJl56eLvKvv/6aoJEEb8OGDSKvWbMmQSNBMtm9e7fIW7duFVn3mUTrh/Vj06ZNIh86dCjitTTdHwBs3rw5ruNzc3NF1mszlilTJq7z+7FkyRKR9WcuhJN+T432HtuvXz+RmzVrFviYguL370cietG50wUAAAAADjHpAgAAAACHmHQBAAAAgEMJ6+mKpkKFCiIncs0I3cP1/vvvi/zyyy+L3KBBA5HHjBkjcvny5YMbHJLWvHnzEj2E68rLyxNZr6+kNW7cWOSyZUvsWwuK0Y4dO0R22eeo15JbvHixyEePHo14/OrVq0Vu0aJFMANDaHTt2lXkFStW+Dp+/fr1Ig8YMEDklJSU6x6bn58v8rp160TW60Rq+lrZ2dkip6WlRTweQPy40wUAAAAADjHpAgAAAACHmHQBAAAAgEMltvHiiSeeSNi1c3JyRJ4wYYLI06dPF/nJJ58UOSsry83AECq1a9dO9BAK6B6uBx98UGS9xlGdOnVE1ut2VapUKcDRobTq06dPzPuOGzdO5GjrJ2q1atXytT9Kn8zMTF/7t2vXTmT92SBSD5e2d+9ekXv16uVrLM8995zITZs29XU8klfh9eHGjx+fwJHER3+/wsKFC0WeNm1axOP135OePXsGMzAfuNMFAAAAAA4x6QIAAAAAh5h0AQAAAIBDCevp8jwvYp49e7bIGRkZzsayYMECkZ999lmRjx07JrJ+NnrSpEluBoakomv48uXLEfdv3769yJcuXQp8TP/QaxgNGzZM5FmzZkU8vkmTJiLr9WZq1qxZ9MEB1zFw4MDrvqaf39e9CjfcEPn/U9TrFjVq1Mjf4FDqtG3bVuSffvop4v5r164V+d133xVZr/u1dOnSgm1dz/rvSbT6Hjt2rMj0cJVedevWLdjW68bq7yQoyXQPV79+/Xwdr9fILVeuXNxj8os7XQAAAADgEJMuAAAAAHCISRcAAAAAOJSwni5rbcR84MABkfXzyYMGDRK5SpUqIutnrWfMmFGwvWHDBvHanj17RNbP9uv1MHRPF2DM1esEffPNNyIfPXo04vHdunUTWf+bePzxx0W+/fbbRS78b0T3l505c0bkaOtqTZ48WeSOHTuKTA8XYhGtzzFa3+PWrVtFLvzeHa3nRUtPTxd5ypQpEfcHtHr16okcra9Ke/PNNyNmP+fWr+u1ExOxBhEQpCVLloj81FNP+Tq+WrVqIr/wwgtxjyle3OkCAAAAAIeYdAEAAACAQ0y6AAAAAMAhq5+5VyK+GI+NGzeK3Lp1a1/H33zzzSKnpqaKvGPHjpjP1aFDh4hZ9wKUcDb6LijEWY3v3r1bZF3jusfL7zoskUQ7V5cuXUQeOnSoyA888ECRr10MqHF/nNV4NIXXHTLm6v7Y4qz5P//8U2T9N6OEocZjV2z13b17d5FXrFgRcf8g61v33TZs2FDkZcuWidygQYMiX6sYUN/+BFbjc+fOFTnaOl3Vq1cXOS0tTeSVK1eK7Od9dd++fSL37t1bZP19CydOnBC5YsWKIletWlXkL7/8UmTdB+/YNWucO10AAAAA4BCTLgAAAABwiEkXAAAAADiUsJ4u/WymXlNi7dq1EY/X49ZrGmm1atUq2Nb9KxkZGRGPTTI8K+1PsfUDnDx5UmT9bLVe/y2e5//r1q0r8mOPPSbyxIkTRa5QoUKRr5UA1Lg/CevpWr9+vci6l1D/HYin5u+66y6RR48eLbLuxylTpkyRr1UMqPHYFVt9nz59WuT+/fuLvHz5cpHj6ekaMGCAyJ06dRJZv6cnGerbn8Bq/PvvvxdZf/bWa+S65PdzvF5366OPPhK5c+fOwQwsGPR0AQAAAEBxY9IFAAAAAA4x6QIAAAAAhxLW06WdOnVK5Gj9LtGeBR03bpzIQ4YMKdiuUaNGkceZBHhW2p+E9btoX3zxhcijRo0Sefv27SK3aNFC5MzMzILt+vXri9caNWoUxBBLCmrcnxJT46tWrRJZ96nE09N14cKFIh9bAlHjsUtYfR8/flzkHj16iLxu3TqRdX2vXr1a5MK95/o9OyUlpcjjLIGob3+c1fjAgQNFnjNnjqtLXcVvT9fixYtF7tq1a+BjChA9XQAAAABQ3Jh0AQAAAIBDJebxQgSG2/b+UOPJhxr3p8TWeFZWlsjDhg0TWT8mq7+Su7CmTZsGN7DEo8ZjV2LrG9dFffvjrMbz8vJEbtKkicj5+fmuLn3V44UjRowQOT09XeQGDRqIHM/j6MWAxwsBAAAAoLgx6QIAAAAAh5h0AQAAAIBD9HSFD89K+0ONJx9q3B9qPPlQ47GjvpMP9e0PNZ586OkCAAAAgOLGpAsAAAAAHGLSBQAAAAAOMekCAAAAAIeYdAEAAACAQ0y6AAAAAMAhJl0AAAAA4BCTLgAAAABwiEkXAAAAADjEpAsAAAAAHGLSBQAAAAAOWc/zEj0GAAAAAAgt7nQBAAAAgENMugAAAADAISZdAAAAAOAQky4AAAAAcIhJFwAAAAA4xKQLAAAAABz6fy7snhHkNIwrAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1152x144 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA10AAACLCAYAAACa9PPwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAVS0lEQVR4nO3deYwUZbfH8fOwiTjsQUBFFIGACHFDcLkRBUyMsogCLsh1QSVGMMQNVAQMLoiC4IJbVISJKMsVNFEkImCiKOJCorgrV64yIpsgq1L3D8bOnONQ0zVdT3V1v99PYt7+TXVXP7yebvrYdeZxQRAIAAAAAMCPGvleAAAAAAAUM5ouAAAAAPCIpgsAAAAAPKLpAgAAAACPaLoAAAAAwCOaLgAAAADwiKYLAAAAADwquKbLObejwj/7nXO7KuQrqnG+Zc65YVXc50Tn3Grn3M7y/z2x+n8CIBw1jmJGfaPYUeModtR49RRc0xUEQck//4jI/4pInwo/K437+ZxzdURkoYjMFpHGIjJTRBaW/xyIHTWOYkZ9o9hR4yh21Hj1FFzTdTDOuRrOudHOue+dc5ucc68655qUH6vrnJtd/vOtzrlVzrnmzrn7ROS/ROTx8u788UpO3UNEaonIo0EQ7AmCYLqIOBE5N6k/GyBCjaO4Ud8odtQ4ih01Hq5omi4RGSEi/UXkbBE5QkS2iMgT5cf+W0QaikgrEWkqIsNFZFcQBHeJyHsiclN5d35TJeftJCJrgiAIKvxsTfnPgSRR4yhm1DeKHTWOYkeNhyimpmu4iNwVBMH6IAj2iMh4EbnEOVdLRPbJgX/BbYMg+DsIgtVBEPyR5XlLRGSb+dk2Eakf07qBbFHjKGbUN4odNY5iR42HqJXvBcSotYj8j3Nuf4Wf/S0izUVklhzorOc45xrJgWtC7wqCYF8W590hIg3MzxqIyPbclwxEQo2jmFHfKHbUOIodNR6imL7p+llEzg+CoFGFf+oGQfB/QRDsC4JgQhAEx4vIGSJyoYgMLX9ccNAzHvCFiHRxzrkKP+tS/nMgSdQ4ihn1jWJHjaPYUeMhiqnpekpE7nPOtRYRcc41c871K799jnOus3Oupoj8IQe+4vynCy8TkTYh510mB7r0kc65Q5xz/1xrutTDnwEIQ42jmFHfKHbUOIodNR6imJquaSKySETeds5tF5GVItKt/FgLEZknB/4lrxWR5XLga85/HneJc26Lc266PWkQBHvlwFDgUBHZKiLXiEj/8p8DSaLGUcyobxQ7ahzFjhoP4fQvAgEAAAAAxKmYvukCAAAAgNSh6QIAAAAAj2i6AAAAAMAjmi4AAAAA8IimCwAAAAA8qlXFcX61YeFxVd8FFVDjhYcaj4YaLzzUePao78JDfUdDjReeSmucb7oAAAAAwCOaLgAAAADwiKYLAAAAADyi6QIAAAAAj2i6AAAAAMAjmi4AAAAA8IimCwAAAAA8oukCAAAAAI9ougAAAADAI5ouAAAAAPCIpgsAAAAAPKLpAgAAAACPaLoAAAAAwCOaLgAAAADwiKYLAAAAADyqle8F+LJ3716VJ06cmLl93333qWM9evRQecGCBSo3bNgw3sUB1fDtt9+qfNxxx6m8cePGzO3FixerY7amBwwYEPpcp59+usrt2rXLep0AgOj279+fub169Wp17N5771X5zjvvVLlWrWgf57p06aLyIYccEunxAKLjmy4AAAAA8IimCwAAAAA8ckEQhB0PPZhmmzZtUrlFixYHvW/Fr/RFRObPn69y//7941uYfy7fCygwqanxPXv2qHz99derbOvysMMOO+jj//jjj5zWUq9ePZVLSkpUfu2111Tu3r17Ts8XETUeTWpqPKrdu3er/NNPP2Vuv/766+rY7bffrnKNGvq/Kd5www0qH3vssSrfeOONKtvXV8Ko8ewVbH1b+/bty9yuW7eu1+caM2aMyhVHMBJAfUeTmhrfunWryo0bN1bZOf2v1vYY9niYW2+9VeWjjz5a5RNPPFHlM888s9rP5UGlT843XQAAAADgEU0XAAAAAHhE0wUAAAAAHhXNTNfOnTtVvuSSS1ResmTJQR/LTNd/tNTU+NixY1W2WxtU5eSTT87cbtWqlTpW1bYH9jUwe/bs0Pvb833xxRcqH3HEEaGPzxE1Hk1qatz6+++/VZ41a5bK48ePV3n9+vUHPVcuswMiIqNGjVJ58uTJkR4fM2o8e6mpb7tVzbp161S2v9bdzhUmOdNlZx4bNWqk8ocffqhymzZt4nx66jua1NS4nelq2rRpnlbyb3PnzlX5oosuUjnhGS9mugAAAAAgaTRdAAAAAOARTRcAAAAAeFSwM13z5s1Tec6cOSovXLgw63PZeRa7n0vPnj1V7tKli8rt2rXL+rkSwLXS0eStxjds2KCy3XPit99+U/mYY45R+c0331S5ZcuWmdt2HqBOnTqha7HvAzNmzFB55MiRKttZnGHDhqn82GOPqRzzfAI1Hk1q38cXLFig8qBBg6p9Ljt7a/eSi+qvv/7K6fE5osazl5r6fvDBB1W+6667VG7QoIHKb731lspdu3bN3LZ7FE2bNi2OJWbt66+/Vrlt27Zxnp76jiY1NW73E33uuedUHjdunMpbtmzxvqaD2bx5s8pVzbbHjJkuAAAAAEgaTRcAAAAAeETTBQAAAAAeFexMV82aNVW2e05EYWe6qjqXneFavHixynaPpIRxrXQ0eavxH3/8UeXjjjtOZbunRD73j5s6darKd9xxh8p2/uWTTz5R2c6r5YgajyY17+N2jrHi3nIi/55jDDNz5kyVL730UpXtDMztt9+e9blFmOkqIInVt92Ha8qUKSpPmDAh9P7WPffco3LFeZjPP/9cHRs+fLjKq1atUrmKz3KR2demfb4cUd/RpOY9vCr2c42dBaw4X37ttdeqY/Z3NWzcuDGntdi53j59+uR0voiY6QIAAACApNF0AQAAAIBHNF0AAAAA4FHBzHQNGTJE5dLSUpVzmek6/PDDVbZ7aXz33XeRzmf3MEoY10pHk7ca/+abb1Tu0KGDyrfccovKkydP9r6mbHXs2FFlu6eL3WPmoYceivPpqfFoUrMX3ejRo1WeNWuWynaO0c7Pvvvuu5nbzZs3D32sfR9ev369ymeccYbKZWVlKp966qkqr1y5UhJEjWcvsfq2M1v33ntvTufr3bu3yi+//HLmduPGjUMfa/9+ePTRR1WeOHGiyrZ+33jjjdDz16tXT+Xly5dnbtt5r2qgvqNJzWdxy77P2jkt+x5/2WWXZW7Pnj1bHdu+fbvKdg8wu++d3TPMsnvqfvDBByrHvH+oxUwXAAAAACSNpgsAAAAAPKLpAgAAAACPUjvTZedd+vXrF3o8ykzX3XffrbL93f3169dXecmSJSrffPPNoee3+yn17ds367XFgGulo8lbjduafv3111VetGiRyhdeeKH3NWXL7i9j5wfsNf8ff/xxnE9PjUeTtxpftmyZyj179lTZ7pFYcQ8XEZEXXnhB5csvvzy2tT3yyCMq23kzu0+XPf7AAw/EtpZKUOPZi62+9+3bp/L06dNVHjNmjMpxz2+vWbMmc7tTp06h9929e7fKdo+7I488UuWdO3eqPGDAAJWXLl0a+nwV53QnTZoUet8sUN/RpGamy9b8jBkzVLafj+0+XRU/C9jP2lWxezHOnTs30uO3bdumcklJSaTHR8RMFwAAAAAkjaYLAAAAADyi6QIAAAAAj1Iz07V161aVTzjhBJXtHip2FsDOdNn9Xa655prMbXvNae3atUPXZq8D7dy5s8q//vqryoceeqjKzzzzjMoDBw5UuWbNmqHPHxHXSkeTWI1v2bJF5TPPPFNlW+OrVq1SuU2bNn4WVg12zxe75xEzXamSt3mAESNGqGyv/7d//wwaNEjlivsW+Xb66aer/NFHH6lsX68rVqzwuRxqPHux1bd9z+3evXtcp67UaaedpvLChQszt+3+oXHbvHmzys2aNQu9//nnn5+5bfdXatSoUdSnp76jSc1Ml/2s3rRp09D728+/dh+vKNauXauy3UvRzjlaCxYsUNnO1ceMmS4AAAAASBpNFwAAAAB4RNMFAAAAAB7VyvcC/mF/97+db6nKRRddpPKLL76ocr169aq1LhGRhg0bqjx16lSV7d4Bf/75p8pXXnmlyuedd57KTZo0qfbaUDheeeUVlb/66iuVr7vuOpXTNMMFZGPXrl0qv/POO5EeP3z48DiXE8lNN92k8tChQ/O0EuSL3acrbnZOq+IMV2XHfYr6Z33zzTczt7///nt17JRTTollTUg/u5+o1bt3b5UHDx4c23N37NhRZbt36bx580If/+mnn6rseaarUnzTBQAAAAAe0XQBAAAAgEc0XQAAAADgUWpmuqI699xzVX722WdVzmWGqyq9evVS+ZxzzlE56hwD/jPY/SoaN26s8m233ZbkcoDY2VmPb775JvT+ffv2Vblbt26xrykuGzZsUHnHjh0ql5SUJLkceHDWWWep7Fy820nZPTqTnOGy7GsPqMwvv/yi8vjx41W2+9La33ng833R7gNZ1UxXGvBNFwAAAAB4RNMFAAAAAB6l9vLC/fv3hx5fsmRJQiv5tyAIVLa/7r6qtU+YMEHladOmxbMwFJSuXbuq3LZt2zytBIjHhx9+GOn+kyZNUrlu3bpxLidWP/zwg8rr1q1TuVOnTkkuBwXg2muvVdnWO5B2Tz/9tMo//fSTyoMGDVLZ/lp3aHzTBQAAAAAe0XQBAAAAgEc0XQAAAADgUWpmup577jmVa9RIbz9ofyX8ihUrVLZrt3ncuHF+FoZU2bt3r8p79uzJ00qAZPz5558q2/lXq3379j6XkxM7m5vmv5OQDnZO96mnnlLZZw2VlZWpfNppp6n8+++/qxz176NRo0Zlbp900kkRV4dCsXv3bpVnzpwZev8bbrjB53KKDn+LAAAAAIBHNF0AAAAA4BFNFwAAAAB4lJqZrtLS0nwvIWPnzp0qr1+/XuWbb7450vlatmypcs2aNau3MBSU5cuXq7x27VqVW7VqleRyYvXKK6+EHq9du3ZCK0GarFy5UmXnXJ5Wkjs7f1PIfxYkw9ZInDNcixcvVvn9998PPW4/t0RVv359lYcNG5a5zXxj8bJzuD///HOeVlKceOUAAAAAgEc0XQAAAADgEU0XAAAAAHiUmpmuNJkyZYrKEyZMiPR4u/fMokWLVG7YsGH1Fgbkib2ue9asWaH3nzFjhs/lAIlr0KBBaEbhs/MsUef4duzYofK6desiPX7s2LGZ23b/z02bNqlsZ8/jtnTpUpU7dOjg9fkA3zp37pzvJfBNFwAAAAD4RNMFAAAAAB7RdAEAAACAR8x0iciQIUNUXr16dU7n69q1q8rt2rXL6XxA0uwM1+TJk1XevHmzyhdccIHKXbp08bMwwJPHHnss9LidUyzkffZQObsHZ1U1YX355Zcqt2nTJuc1JaVPnz4qt23bNk8rQSH59NNPVe7Ro0d+FlIJO4doP6fkA990AQAAAIBHNF0AAAAA4BFNFwAAAAB4lJqZLrs/xv79+0Pv//nnn4ce79evn8p2RiXsuWrUyK0Xfemll3J6PIqDnflI8/5s9jUwadIklZ988kmVW7durbKdfcj1NYTCZGf/li9frnJZWZnKt912W+jjk/TLL7+o3KJFC5UvvvjiJJeDPLjiiitUjjrTlWaHH364yt26dVN59uzZKpeUlHhfEwrf1KlTVb766qtVbtSokbfn/uSTT0KP9+3bV+W6det6W0u2+GQEAAAAAB7RdAEAAACARzRdAAAAAOCRs7NURujBOM2ZM0flK6+8MvT+cc5h5Xquu+++W+Vx48ZVey0xcPl88gKUWI2ffPLJKts6W7Fihcr16tWL7bntvIqd0frggw9Ufvfdd0PP99VXX6ncvn37HFYXGTUeTWI1bi1btkzlnj17qmxr3O5z5HMvrNGjR6ts58mGDx+u8hNPPOFtLZWgxrMXW31v2LBB5f79+6u8atWquJ7Ku6OOOkrlt956S+WOHTsmuRyL+o4msffwXbt2qRx1tq958+Yq33///SpfddVVmdufffaZOmZff9aUKVNUfu+991S2e+Laz1Q+58sqUWmN800XAAAAAHhE0wUAAAAAHtF0AQAAAIBHqZnp2rZtm8qdO3dW+ddff1XZ50zXkUceqbLdz+Lpp59WuX79+irXrl272muJAddKR5O3mS57PfPZZ5+tcpzzLG+//bbKv/32W+j97XXZQ4cOVXnixIkqJ1zz1Hg0eZvp2rJli8rjx49X+fHHH1e5tLRU5UsvvTS2tdg5RPt6szW8evVqle1rwjNqPHve6vv3339X+dRTT1U5bP9P3+rUqaOy3QfSzlN26NDB95KioL6jSew93PYEdi9Fuy9XVWrV0tsBV3wfta+vPXv2RDq39eqrr6qc570VmekCAAAAgKTRdAEAAACARzRdAAAAAOBRama6rG+//VblefPmqWz3xopzpmv+/Pkq2706Uo5rpaNJrMY/+ugjle210nbPCZ/s66VZs2YqP/DAAypX3FsjBajxaPL2Pm5t3bpVZTsvu3HjRpXHjh2r8qhRow56bjsfYPf8Gjx4cOhzPfjggyrfeuutB32uBFDj2Uusvm3N9OnTR2Wf+3gNGDAgNF922WXentsD6juavL2HL126VOXevXvnaSX/9sILL6g8ZMgQlXPpC2LATBcAAAAAJI2mCwAAAAA8oukCAAAAAI9SO9NVlTVr1qg8ffp0lWfOnKlyxZmUkSNHqmP2/4PWrVurbPe/SDmulY4mbzW+fft2le210nYGLBdjxoxRuXv37irb2YSUo8ajSe37+I4dO1QeMWKEygsXLlT5+OOPz9wePXq0Onb99derXNVedHbvuYcffljlJk2ahD7eM2o8e3mr7w0bNqj8/vvvqzxw4MDQx9sZFPvZpKL27durbPcHLTDUdzR5q3H7+djONbZs2TKxtTz//PMq2/dw51JVVsx0AQAAAEDSaLoAAAAAwKOCvbwQB5Wq71cLADVeeKjxaAqmxnfv3q1yWVmZyvfcc0/mdmlpqTpmf+W7ZS/1atWqlcp5/vXCFjWevYKpb2RQ39Gkpsbte7S93HDdunUq20tmzzrrrMztCy64QB3r1atX6HPb9+iUXU5ocXkhAAAAACSNpgsAAAAAPKLpAgAAAACPmOkqPqm+yDWFqPHCQ41HQ40XHmo8e9R34aG+o6HGCw8zXQAAAACQNJouAAAAAPCIpgsAAAAAPKLpAgAAAACPaLoAAAAAwCOaLgAAAADwiKYLAAAAADyi6QIAAAAAj2i6AAAAAMAjmi4AAAAA8IimCwAAAAA8ckEQ5HsNAAAAAFC0+KYLAAAAADyi6QIAAAAAj2i6AAAAAMAjmi4AAAAA8IimCwAAAAA8oukCAAAAAI/+H5gIJKze+R5FAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1152x144 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x144 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA10AAACLCAYAAACa9PPwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAMbklEQVR4nO3db6iV1Z4H8N8y0yC1WzEqUyIOlTGQUUiCYjGZLyaiKb1gkk2R94Uc7UVQkF2ikbjFUBANKsN9EfQHGid1SCXoMsf+TFZiCUPSJFZMOGETDooZVqbPvNA2rn0923P0rGe7n/P5gLC+ruec81N/HvaPZ6/zpKqqAgAAgDJGdbsAAACAJjN0AQAAFGToAgAAKMjQBQAAUJChCwAAoCBDFwAAQEGGLgAAgIJ6buhKKR0+5dfxlNKRU/K9Z/H53kkp/e4M1/wxpbT75Nd74KyLh0HQ4zSZ/qbp9DhNp8fPzuhuFzBUVVWN+3WdUvrviPhdVVX/XvjL/mdErIuIfyz8dUCP02j6m6bT4zSdHj87PXenayAppVEppcdSSl+mlP4vpfSvKaXLTu5dlFJ69eTvH0wp7UgpTUop/SEi5kbE6pPT+erTfe6qqtZUVdUfET/W+EeCjB6nyfQ3TafHaTo93lljhq6IeCgi7oqIWyLiLyPiQESsObl3f0RcEhFTIuLyiFgWEUeqqvp9RPxHRKyoqmpcVVUraq8aBk+P02T6m6bT4zSdHu+gSUPXsoj4fVVV/1NV1U8R8Q8R8duU0uiIOBon/oGvqqrqWFVVn1RVdaiLtcLZ0OM0mf6m6fQ4TafHO+i5M10dTI2If0spHT/l945FxKSIeCVOTNb/klL6TUS8Giea4mj9ZcJZ0+M0mf6m6fQ4TafHO2jSna69EfG3VVX95pRfF1VV9U1VVUerqlpVVdVfR8TsiLgjIv7+5MdVXasYhkaP02T6m6bT4zSdHu+gSUPXP0fEH1JKUyMiUkp/kVL6u5Prv0kpXZdSuiAiDsWJW5y/TuH/GxF/1ekTp5TGpJQuiogUEReePAzYpL87eoMep8n0N02nx2k6Pd5BTxV7Bi9ExKaI+FNK6fuI+CgiZp3cmxwR6+PEP/J/RcS7ceI2568f99uU0oGU0j8N8Ln/FBFH4sRk/seT65tL/CGgAz1Ok+lvmk6P03R6vINUVSPijh4AAEBXNOlOFwAAwHnH0AUAAFCQoQsAAKAgQxcAAEBBhi4AAICCRp9h34827D2p2wX0GD3ee/T40Ojx3qPHB09/9x79PTR6vPectsfd6QIAACjI0AUAAFCQoQsAAKAgQxcAAEBBhi4AAICCDF0AAAAFGboAAAAKMnQBAAAUZOgCAAAoyNAFAABQkKELAACgIEMXAABAQYYuAACAggxdAAAABRm6AAAAChrd7QLOR/v378/yxIkTs/z6669neeHChcVrAhjp1q5d21ovX74821uwYEGWN2zYUEtNMFjXXXddlj/77LMsHzlypLUeM2ZMLTUB9XGnCwAAoCBDFwAAQEHeXngau3fvzvKoUflseuWVV9ZZDgy7nTt3ZnnmzJlZ3rhxY5bvvPPOLLf/n4A69Pf3D7jX3rPt38enT59epCYYrJRSx/zhhx+21rfcckstNUFJt956a5YnTJjQWr/00kvZ3iWXXFJLTd3klRMAAEBBhi4AAICCDF0AAAAFOdN1Gtu3b8/y+PHjszxr1qw6y4FzduqPIo4482MO2n/89k8//ZRlZ7rohvZzW520n/9ypotumzx5cpbbf2T8vHnzWutffvmllpqgTps3b26tX3755WzvoYceqruc2nnlBAAAUJChCwAAoCBDFwAAQEHOdEXEvn37svzkk09m+eGHH66zHBh2n376aZa//vrrjtevWLEiy6NH+1ZBb+nr6+t2CZB5+umns/zoo49medu2ba314cOHs71x48aVKwwKeeSRR7L8zjvvtNbfffddzdV0nztdAAAABRm6AAAACjJ0AQAAFOSgRvz5+ZYffvghy0uWLKmzHDhn7c94eeyxx4b08UuXLs1ySumcawIYyWbOnJnlZ599Nstz5swZcG/VqlXlCoOajPTXEu50AQAAFGToAgAAKMjQBQAAUFCqqqrTfsfNppg3b16W9+7dm+Vdu3ZlecyYMcVrOgcj+w2zQ9fIHm8/pzht2rSO17c/h+vnn38e9pqGkR4fmsb0+Nq1a1vr5cuXd7x2zZo1We6x53bp8cHr2f7esGFDlhctWtRajx8/Pts7cOBALTXVRH8PTc/2ePuzuCZPntxat5/vOnbsWC011eS0Pe5OFwAAQEGGLgAAgIIMXQAAAAWNyOd0HTx4MMtvv/12lmfMmJHl8/wMF/yZjRs3Dun6e+65p1AlMHzOdI4Lesnzzz/f7RKgqIkTJ2b51HNc7We6tm/fnuVZs2aVK6xL3OkCAAAoyNAFAABQkKELAACgoBF5pmvnzp0d96dMmVJTJVBGf39/x/2xY8dm+ZlnnilZDgBtlixZkuWPPvqoS5VAPVauXNlat7/uOHUvImLr1q211FQnd7oAAAAKMnQBAAAUZOgCAAAoaESe6dqxY0fH/VWrVtVUCQyfr776qrV+8803O147bty4LF9xxRVFagLg9Pbs2dPtEqBr2p/TNRK40wUAAFCQoQsAAKAgQxcAAEBBI+ZM16nnXZ577rlsb+7cuVmeMWNGLTXBcPrkk08Gfe0TTzxRsBIAzmT9+vUD7h06dCjLW7ZsyfIdd9xRpCYoaf78+a11+3O6Dh48mOWjR49m+cILLyxXWE3c6QIAACjI0AUAAFDQiHl7YX9/f2u9f//+bO/666/P8ujRI+avhQbZtm3bgHuXXXZZlh944IHC1UB39fX1dbsE6Oi9997L8sqVK1vr1157LdvbvHlzlr29kF40e/bs1vrGG2/M9nbu3Jnlb7/9NstTpkwpV1hN3OkCAAAoyNAFAABQkKELAACgoBFzeOnjjz9urVNK2d6SJUvqLgfO2RdffJHl1atXD3ht+5muCRMmFKkJgMGZOnVqlm+77bbWet26ddneW2+9VUtNUNKpP/Z9/Pjx2V5VVVn+4IMPsrxo0aJyhdXEnS4AAICCDF0AAAAFGboAAAAKauyZrsOHD2d5y5YtrXX7c7luuummWmqC4XTw4MEsHz9+fMBrFy5cWLocAIBBaX8t/u6772Z5165dWXamCwAAgI4MXQAAAAUZugAAAApq7Jmu9evXZ3nfvn2t9eLFi+suB4bdq6++OuBe+3O5li1bVrocAIBBmT9/fpZfeOGFLlVSH3e6AAAACjJ0AQAAFGToAgAAKKixZ7q+/PLLAfcuv/zyGiuB4XHo0KEsr169esBrr7rqqixPnTq1SE1QpwULFrTWGzdu7Hjt2rVrs9zX11ekJgDOXUopy+3P6WoCd7oAAAAKMnQBAAAUZOgCAAAoqLFnul555ZUB9+6+++4aK4Hh0f7+5uPHjw947b333lu6HACGUfs5xFP9+OOPWW4/4zthwoQiNUFdqqrK8qZNm7pUSTnudAEAABRk6AIAACjI0AUAAFBQY8507dmzJ8vffPNNlyqBMvbv399xf9KkSa310qVLS5cDxe3evTvLZ3o2F/SySy+9dMC99u//O3bsyPK8efOK1AR1aX9OV3tuAne6AAAACjJ0AQAAFGToAgAAKKgxZ7o2bNiQ5WPHjmV57ty5rfU111xTS00wnN54442O+9dee21rPXbs2NLlQHGPP/54t0uA2ixevLi13rp1axcrgfJmzpyZ5fZnj44a1bz7Qs37EwEAAJxHDF0AAAAFGboAAAAK6tkzXUePHs3yunXrOl5///33t9ZNfJ8ozdN+LnHXrl0dr7/44otb6wsuuKBITVDSuTyX6/PPP8/y9OnTh6UmAIbfxIkTs9z+2txzugAAABgSQxcAAEBBhi4AAICCevZMV/t7PydPnpzlG264Icv33Xdf8ZpgOLW/n/nmm2/O8o4dO7LsDAtNt2bNmta6r6+vi5XA8JszZ05rffvtt2d777//fpY9b5SmefDBB7P84osvZnnPnj1Zvvrqq4vXNNzc6QIAACjI0AUAAFBQqqqq037HTc5LzfsZm2X1TI9///33WX7qqaeyPHv27Nb6rrvuqqWmLtHjQ9MzPU6LHh88/d179PfQjIge37t3b5anTZuW5U2bNmW5/S2455nT9rg7XQAAAAUZugAAAAoydAEAABTkTFfzeK/00Ojx3qPHh0aP9x49Pnj6u/fo76HR473HmS4AAIC6GboAAAAKMnQBAAAUZOgCAAAoyNAFAABQkKELAACgIEMXAABAQYYuAACAggxdAAAABRm6AAAACjJ0AQAAFJSqqup2DQAAAI3lThcAAEBBhi4AAICCDF0AAAAFGboAAAAKMnQBAAAUZOgCAAAo6P8BKnNyAG/M8HoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1152x144 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEGjaUcHuhnt"
      },
      "source": [
        "## I layer TripletLoss e PredictionLayer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_spQKNTci5I"
      },
      "source": [
        "class TripletLossLayer(Layer):\n",
        "    \"\"\"\n",
        "        Layer object to minimise the triplet loss.\n",
        "        Here we implement the Bayesian Personal Ranking triplet loss.\n",
        "    \"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        super(TripletLossLayer, self).__init__(**kwargs)\n",
        "    \n",
        "    def triplet_loss(self, inputs):\n",
        "        \"\"\"\n",
        "            Triplet loss function.\n",
        "            We make use of log-loss for numerical purposes.\n",
        "        \"\"\"\n",
        "        anchor, positive, negative = inputs\n",
        "        p_score = tf.math.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis = -1)\n",
        "        n_score = tf.math.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis = -1)\n",
        "        return tf.reduce_sum(tf.maximum(tf.subtract(p_score, n_score) , 0))\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        loss = self.triplet_loss(inputs)\n",
        "        self.add_loss(loss)\n",
        "        return loss\n",
        "\n",
        "class PredictionLayer(Layer):\n",
        "    \"\"\"\n",
        "        Layer object to predict positive matches.\n",
        "    \"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        super(PredictionLayer, self).__init__(**kwargs)\n",
        "    \n",
        "    def rec_similarity(self, inputs):\n",
        "        \"\"\"\n",
        "            rec_similarity function\n",
        "        \"\"\"\n",
        "        anchor, item = inputs\n",
        "        score = tf.math.reduce_sum(tf.square(tf.subtract(anchor, item)), axis = -1)\n",
        "        return score\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        pred = self.rec_similarity(inputs)\n",
        "        return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd3UIa7bsM9F"
      },
      "source": [
        "### Costruire le reti di training a predizione\n",
        "\n",
        "Nelle celle seguenti dovrete costruire (tramite funzione) due reti (**che condividano i pesi**) una per il training (che quindi abbia come input delle triplette) e una per il predict (che abbia come input due sole immagini e restituisca il loro score di *vicinanza*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8KRIc8Ys06l"
      },
      "source": [
        "def buildPredictNetwork(input_shape, embeddingsize):\n",
        "    '''\n",
        "    Define the neural network to learn image similarity\n",
        "    Input : \n",
        "            input_shape : shape of input images\n",
        "            embeddingsize : vectorsize used to encode our picture   \n",
        "    '''\n",
        "    # Convolutional Neural Network\n",
        "    network = Sequential()\n",
        "    \n",
        "    ## YOUR CODE HERE ##\n",
        "\n",
        "    return network\n",
        "\n",
        "def buildTrainingNetwork(input_shape, network, margin=0.2):\n",
        "    '''\n",
        "    Define the Keras Model for training \n",
        "        Input : \n",
        "            input_shape : shape of input images\n",
        "            network : Neural network to train outputing embeddings\n",
        "            margin : minimal distance between Anchor-Positive and Anchor-Negative for the lossfunction (alpha)\n",
        "    \n",
        "    '''\n",
        "    # Define the tensors for the three input images\n",
        "    anchor_input = Input(input_shape, name=\"anchor_input\")\n",
        "    positive_input = Input(input_shape, name=\"positive_input\")\n",
        "    negative_input = Input(input_shape, name=\"negative_input\") \n",
        "    \n",
        "    # Generate the encodings (feature vectors) for the three images\n",
        "    encoded_a = network(anchor_input)\n",
        "    encoded_p = network(positive_input)\n",
        "    encoded_n = network(negative_input)\n",
        "    \n",
        "    # TripletLoss Layer\n",
        "    loss_layer = TripletLossLayer(alpha=margin, name='triplet_loss_layer')([encoded_a, encoded_p, encoded_n])\n",
        "    \n",
        "    # Connect the inputs with the outputs\n",
        "    network_train = Model(inputs=[anchor_input,positive_input,negative_input],outputs=loss_layer)\n",
        "    \n",
        "    # return the model\n",
        "    return network_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKuoSX8putTE"
      },
      "source": [
        "## Compilare il modello\n",
        "\n",
        "Dopo l'esecuzione della cella in basso, il tipo di grafico del modello dovrebbe essere questo.\n",
        "\n",
        "![](https://github.com/CrimyTheBold/tripletloss/raw/8fa17e4cabf80343b5f766fb88a41bc067d7946a/02%20model.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyrog7mnuwQ0"
      },
      "source": [
        "network_predict = build_network(input_shape,embeddingsize=10)\n",
        "network_train = build_model(input_shape,network_predict)\n",
        "optimizer = Adam(lr = 0.00006)\n",
        "network_train.compile(loss=None,optimizer=optimizer)\n",
        "network_train.summary()\n",
        "plot_model(network_train,show_shapes=True, show_layer_names=True, to_file='model.png')\n",
        "print(network_train.metrics_names)\n",
        "n_iteration=0\n",
        "\n",
        "# The last line only works for my model. Available after solutions are given.\n",
        "# network_train.load_weights('mnist-160k_weights.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amh9BYFIvyUY"
      },
      "source": [
        "#### Verificare che i modelli condividano i pesi\n",
        "\n",
        "Potete verificare che i modelli train e predict condividano i layer in modo che allenare il primo aggiorni i pesi del secondo. Tramite questa cella stampate le posizioni di memoria dei layer e verificate che corrispondano."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08tSEjAlwGiB"
      },
      "source": [
        "network_train.layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccorYoLEwFMd"
      },
      "source": [
        "network_predict.layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDM7I_w0vXXa"
      },
      "source": [
        "## Costruire il training set\n",
        "\n",
        "Dobbiamo costruire delle triplette per allenare il modello. Utilizzeremo delle funzioni per costruire batch di triplette su cui svolgeremo il training.\n",
        "\n",
        "Prima costruiremo delle triplette random, poi batch di triplette \"hard\" che allenano il modello in modo più efficiente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FcX3t7cwiHD"
      },
      "source": [
        "def get_batch_random(batch_size,s=\"train\"):\n",
        "    \"\"\"\n",
        "    Create batch of APN triplets with a complete random strategy\n",
        "    \n",
        "    Arguments:\n",
        "    batch_size -- integer \n",
        "\n",
        "    Returns:\n",
        "    triplets -- list containing 3 tensors A,P,N of shape (batch_size,w,h,c)\n",
        "    \"\"\"\n",
        "    if s == 'train':\n",
        "        X = dataset_train\n",
        "    else:\n",
        "        X = dataset_test\n",
        "\n",
        "    m, w, h, c = X[0].shape\n",
        "    \n",
        "    \n",
        "    # initialize result\n",
        "    triplets=[np.zeros((batch_size,h, w,c)) for i in range(3)]\n",
        "    \n",
        "    for i in range(batch_size):\n",
        "        #Pick one random class for anchor\n",
        "        ## YOUR CODE HERE ##\n",
        "        \n",
        "        #Pick two different random pics for this class => A and P\n",
        "        [idx_A,idx_P] =  ## YOUR CODE HERE ##\n",
        "        \n",
        "        #Pick another class for N, different from anchor_class\n",
        "        negative_class = (anchor_class + np.random.randint(1,n_classes)) % n_classes\n",
        "        nb_sample_available_for_class_N = X[negative_class].shape[0]\n",
        "        \n",
        "        #Pick a random pic for this negative class => N\n",
        "        idx_N =  ## YOUR CODE HERE ##\n",
        "\n",
        "        triplets[0][i,:,:,:] = X[anchor_class][idx_A,:,:,:]\n",
        "        triplets[1][i,:,:,:] = X[anchor_class][idx_P,:,:,:]\n",
        "        triplets[2][i,:,:,:] = X[negative_class][idx_N,:,:,:]\n",
        "\n",
        "    return triplets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "878NjmcvxD_S"
      },
      "source": [
        "Una funzione per visualizzare le triplette scelte."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMw5HIn3xII4"
      },
      "source": [
        "def drawTriplets(tripletbatch, nbmax=None):\n",
        "    \"\"\"display the three images for each triplets in the batch\n",
        "    \"\"\"\n",
        "    labels = [\"Anchor\", \"Positive\", \"Negative\"]\n",
        "\n",
        "    if (nbmax==None):\n",
        "        nbrows = tripletbatch[0].shape[0]\n",
        "    else:\n",
        "        nbrows = min(nbmax,tripletbatch[0].shape[0])\n",
        "                 \n",
        "    for row in range(nbrows):\n",
        "        fig=plt.figure(figsize=(16,2))\n",
        "    \n",
        "        for i in range(3):\n",
        "            subplot = fig.add_subplot(1,3,i+1)\n",
        "            axis(\"off\")\n",
        "            plt.imshow(tripletbatch[i][row,:,:,0],vmin=0, vmax=1,cmap='Greys')\n",
        "            subplot.title.set_text(labels[i])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAhSogrgxR-V"
      },
      "source": [
        "Per costruire *hard triplets* dobbiamo prendere esempi negativi e positivi i più vicini possibili tra loro. Per fare ciò calcoliamo la distanza tramite una funzione `compute_dist`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU-cjVtOxIph"
      },
      "source": [
        "# Computing distance\n",
        "def compute_img_dist(a,b):\n",
        "    return np.sum(np.square(a-b), axis = 1)\n",
        "\n",
        "def get_batch_hard(draw_batch_size, hard_batchs_size, norm_batchs_size, network = network_predict, s=\"train\"):\n",
        "    \"\"\"\n",
        "    Create batch of APN \"hard\" triplets\n",
        "    \n",
        "    Arguments:\n",
        "    draw_batch_size -- integer : number of initial randomly taken samples   \n",
        "    hard_batchs_size -- interger : select the number of hardest samples to keep\n",
        "    norm_batchs_size -- interger : number of random samples to add\n",
        "\n",
        "    Returns:\n",
        "    triplets -- list containing 3 tensors A,P,N of shape (hard_batchs_size+norm_batchs_size,w,h,c)\n",
        "    \"\"\"\n",
        "    if s == 'train':\n",
        "        X = dataset_train\n",
        "    else:\n",
        "        X = dataset_test\n",
        "\n",
        "    m, w, h, c = X[0].shape\n",
        "    \n",
        "    \n",
        "    # Step 1 : pick a random batch to study\n",
        "    ## YOUR CODE HERE ##\n",
        "    \n",
        "    # Step 2 : compute the loss with current network : d(A,P)-d(A,N). The alpha parameter here is omited here since we want only to order them\n",
        "    studybatchloss = np.zeros((draw_batch_size))\n",
        "    \n",
        "    # Compute embeddings for anchors, positive and negatives\n",
        "    A = network.predict(studybatch[0])\n",
        "    P = network.predict(studybatch[1])\n",
        "    N = network.predict(studybatch[2])\n",
        "    \n",
        "    # Compute d(A,P)-d(A,N)\n",
        "    studybatchloss = ## YOUR CODE HERE ##\n",
        "    \n",
        "    # Sort by distance (high distance first) and take the index\n",
        "    selection = np.argsort(studybatchloss)[::-1][:hard_batchs_size]\n",
        "    \n",
        "    # Draw other random samples from the batch\n",
        "    selection2 = np.random.choice(np.delete(np.arange(draw_batch_size),selection),norm_batchs_size,replace=False)\n",
        "    \n",
        "    selection = np.append(selection,selection2)\n",
        "    \n",
        "    triplets = ## YOUR CODE HERE ##\n",
        "    \n",
        "    return triplets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP50XFNEydGl"
      },
      "source": [
        "Verifichiamo con un plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKA7bqRDygIK"
      },
      "source": [
        "triplets = get_batch_random(2)\n",
        "print(\"Checking batch width, should be 3 : \",len(triplets))\n",
        "print(\"Shapes in the batch A:{0} P:{1} N:{2}\".format(triplets[0].shape, triplets[1].shape, triplets[2].shape))\n",
        "drawTriplets(triplets)\n",
        "hardtriplets = get_batch_hard(50,1,1,network)\n",
        "print(\"Shapes in the hardbatch A:{0} P:{1} N:{2}\".format(hardtriplets[0].shape, hardtriplets[1].shape, hardtriplets[2].shape))\n",
        "drawTriplets(hardtriplets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYE5WDdwylE8"
      },
      "source": [
        "Esempio di iperparametri, cmbiateli secondo il vostro modello."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YBbf_x3ypLo"
      },
      "source": [
        "# Hyper parameters\n",
        "evaluate_every = 1000 # interval for evaluating on one-shot tasks\n",
        "batch_size = 32\n",
        "n_iter = 80000 # No. of training iterations\n",
        "n_val = 250 # how many one-shot tasks to validate on"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb5_BimAywgg"
      },
      "source": [
        "#### Validazione"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEeERMAjyyVC"
      },
      "source": [
        "# Computing embeddings distance\n",
        "def compute_dist(a,b):\n",
        "    return np.sum(np.square(a-b))\n",
        "\n",
        "def compute_probs(network,X,Y):\n",
        "    '''\n",
        "    Input\n",
        "        network : current NN to compute embeddings\n",
        "        X : tensor of shape (m,w,h,1) containing pics to evaluate\n",
        "        Y : tensor of shape (m,) containing true class\n",
        "        \n",
        "    Returns\n",
        "        probs : array of shape (m,m) containing distances\n",
        "    \n",
        "    '''\n",
        "    m = X.shape[0]\n",
        "    nbevaluation = int(m*(m-1)/2)\n",
        "    probs = np.zeros((nbevaluation))\n",
        "    y = np.zeros((nbevaluation))\n",
        "    \n",
        "    #Compute all embeddings for all pics with current network\n",
        "    embeddings = network.predict(X)\n",
        "    \n",
        "    size_embedding = embeddings.shape[1]\n",
        "    \n",
        "    #For each pics of our dataset\n",
        "    k = 0\n",
        "    for i in range(m):\n",
        "            #Against all other images\n",
        "            for j in range(i+1,m):\n",
        "                #compute the probability of being the right decision : it should be 1 for right class, 0 for all other classes\n",
        "                probs[k] = -compute_dist(embeddings[i,:],embeddings[j,:])\n",
        "                if (Y[i]==Y[j]):\n",
        "                    y[k] = 1\n",
        "                    #print(\"{3}:{0} vs {1} : {2}\\tSAME\".format(i,j,probs[k],k))\n",
        "                else:\n",
        "                    y[k] = 0\n",
        "                    #print(\"{3}:{0} vs {1} : \\t\\t\\t{2}\\tDIFF\".format(i,j,probs[k],k))\n",
        "                k += 1\n",
        "    return probs,y\n",
        "#probs,yprobs = compute_probs(network,x_test_origin[:10,:,:,:],y_test_origin[:10])\n",
        "\n",
        "def compute_metrics(probs,yprobs):\n",
        "    '''\n",
        "    Returns\n",
        "        fpr : Increasing false positive rates such that element i is the false positive rate of predictions with score >= thresholds[i]\n",
        "        tpr : Increasing true positive rates such that element i is the true positive rate of predictions with score >= thresholds[i].\n",
        "        thresholds : Decreasing thresholds on the decision function used to compute fpr and tpr. thresholds[0] represents no instances being predicted and is arbitrarily set to max(y_score) + 1\n",
        "        auc : Area Under the ROC Curve metric\n",
        "    '''\n",
        "    # calculate AUC\n",
        "    auc = roc_auc_score(yprobs, probs)\n",
        "    # calculate roc curve\n",
        "    fpr, tpr, thresholds = roc_curve(yprobs, probs)\n",
        "    \n",
        "    return fpr, tpr, thresholds, auc\n",
        "\n",
        "def compute_interdist(network):\n",
        "    '''\n",
        "    Computes sum of distances between all classes embeddings on our reference test image: \n",
        "        d(0,1) + d(0,2) + ... + d(0,9) + d(1,2) + d(1,3) + ... d(8,9)\n",
        "        A good model should have a large distance between all theses embeddings\n",
        "        \n",
        "    Returns:\n",
        "        array of shape (n_classes, n_classes) \n",
        "    '''\n",
        "    res = np.zeros((n_classes, n_classes))\n",
        "    \n",
        "    ref_images = np.zeros((n_classes, img_rows, img_cols,1))\n",
        "    \n",
        "    #generates embeddings for reference images\n",
        "    for i in range(n_classes):\n",
        "        ref_images[i,:,:,:] = dataset_test[i][0,:,:,:]\n",
        "    ref_embeddings = network.predict(ref_images)\n",
        "    \n",
        "    for i in range(n_classes):\n",
        "        for j in range(n_classes):\n",
        "            res[i,j] = compute_dist(ref_embeddings[i], ref_embeddings[j])\n",
        "    return res\n",
        "\n",
        "def draw_interdist(network,n_iteration):\n",
        "    interdist = compute_interdist(network)\n",
        "    \n",
        "    data = []\n",
        "    for i in range(n_classes):\n",
        "        data.append(np.delete(interdist[i,:],[i]))\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.set_title('Evaluating embeddings distance from each other after {0} iterations'.format(n_iteration))\n",
        "    ax.set_ylim([0,3])\n",
        "    plt.xlabel('Classes')\n",
        "    plt.ylabel('Distance')\n",
        "    ax.boxplot(data,showfliers=False,showbox=True)\n",
        "    locs, labels = plt.xticks()\n",
        "    plt.xticks(locs,np.arange(n_classes))\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "def find_nearest(array,value):\n",
        "    idx = np.searchsorted(array, value, side=\"left\")\n",
        "    if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
        "        return array[idx-1],idx-1\n",
        "    else:\n",
        "        return array[idx],idx\n",
        "    \n",
        "def draw_roc(fpr, tpr,thresholds):\n",
        "    #find threshold\n",
        "    targetfpr=1e-3\n",
        "    _, idx = find_nearest(fpr,targetfpr)\n",
        "    threshold = thresholds[idx]\n",
        "    recall = tpr[idx]\n",
        "    \n",
        "    \n",
        "    # plot no skill\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "    # plot the roc curve for the model\n",
        "    plt.plot(fpr, tpr, marker='.')\n",
        "    plt.title('AUC: {0:.3f}\\nSensitivity : {2:.1%} @FPR={1:.0e}\\nThreshold={3})'.format(auc,targetfpr,recall,abs(threshold) ))\n",
        "    # show the plot\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZZhi-7AzXgE"
      },
      "source": [
        "#Testing on an untrained network\n",
        "probs,yprob = compute_probs(network_predict,x_test_origin[:500,:,:,:],y_test_origin[:500])\n",
        "fpr, tpr, thresholds,auc = compute_metrics(probs,yprob)\n",
        "draw_roc(fpr, tpr,thresholds)\n",
        "draw_interdist(network_predict,n_iteration)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UD1QnM5MziAM"
      },
      "source": [
        "def DrawTestImage(network, images, refidx=0):\n",
        "    '''\n",
        "    Evaluate some pictures vs some samples in the test set\n",
        "        image must be of shape(1,w,h,c)\n",
        "    \n",
        "    Returns\n",
        "        scores : resultat des scores de similarités avec les images de base => (N)\n",
        "    \n",
        "    '''\n",
        "    N=4\n",
        "    _, w,h,c = dataset_test[0].shape\n",
        "    nbimages=images.shape[0]\n",
        "    \n",
        "    #generates embedings for given images\n",
        "    image_embedings = network.predict(images)\n",
        "    \n",
        "    #generates embedings for reference images\n",
        "    ref_images = np.zeros((nb_classes,w,h,c))\n",
        "    for i in range(nb_classes):\n",
        "        ref_images[i,:,:,:] = dataset_test[i][refidx,:,:,:]\n",
        "    ref_embedings = network.predict(ref_images)\n",
        "            \n",
        "    for i in range(nbimages):\n",
        "        #Prepare the figure\n",
        "        fig=plt.figure(figsize=(16,2))\n",
        "        subplot = fig.add_subplot(1,nb_classes+1,1)\n",
        "        axis(\"off\")\n",
        "        plotidx = 2\n",
        "            \n",
        "        #Draw this image    \n",
        "        plt.imshow(images[i,:,:,0],vmin=0, vmax=1,cmap='Greys')\n",
        "        subplot.title.set_text(\"Test image\")\n",
        "            \n",
        "        for ref in range(nb_classes):\n",
        "            #Compute distance between this images and references\n",
        "            dist = compute_dist(image_embedings[i,:],ref_embedings[ref,:])\n",
        "            #Draw\n",
        "            subplot = fig.add_subplot(1,nb_classes+1,plotidx)\n",
        "            axis(\"off\")\n",
        "            plt.imshow(ref_images[ref,:,:,0],vmin=0, vmax=1,cmap='Greys')\n",
        "            subplot.title.set_text((\"Class {0}\\n{1:.3e}\".format(ref,dist)))\n",
        "            plotidx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gVJGRY3zk8U"
      },
      "source": [
        "for i in range(3):\n",
        "    DrawTestImage(network,np.expand_dims(dataset_train[i][0,:,:,:],axis=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DAvDT0zznP8"
      },
      "source": [
        "### Train del modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8yzGPjZzoza"
      },
      "source": [
        "print(\"Starting training process!\")\n",
        "print(\"-------------------------------------\")\n",
        "t_start = time.time()\n",
        "dummy_target = [np.zeros((batch_size,15)) for i in range(3)]\n",
        "for i in range(1, n_iter+1):\n",
        "    triplets = get_batch_hard(200,16,16,network)\n",
        "    loss = network_train.train_on_batch(triplets, None)\n",
        "    n_iteration += 1\n",
        "    if i % evaluate_every == 0:\n",
        "        print(\"\\n ------------- \\n\")\n",
        "        print(\"[{3}] Time for {0} iterations: {1:.1f} mins, Train Loss: {2}\".format(i, (time.time()-t_start)/60.0,loss,n_iteration))\n",
        "        probs,yprob = compute_probs(network,x_test_origin[:n_val,:,:,:],y_test_origin[:n_val])\n",
        "        #fpr, tpr, thresholds,auc = compute_metrics(probs,yprob)\n",
        "        #draw_roc(fpr, tpr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3itDW12zwYL"
      },
      "source": [
        "### Validazione"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MdSl-vZzzFR"
      },
      "source": [
        "#Full evaluation\n",
        "probs,yprob = compute_probs(network,x_test_origin,y_test_origin)\n",
        "fpr, tpr, thresholds,auc = compute_metrics(probs,yprob)\n",
        "draw_roc(fpr, tpr,thresholds)\n",
        "draw_interdist(network,n_iteration)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GNqFuupz5Im"
      },
      "source": [
        "for i in range(3):\n",
        "    DrawTestImage(network,np.expand_dims(dataset_train[i][0,:,:,:],axis=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs-hN6Pez9FX"
      },
      "source": [
        "draw_interdist(network_predict,n_iteration)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}